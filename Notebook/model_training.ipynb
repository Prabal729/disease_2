{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9388d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèãÔ∏è Model Training Pipeline\n",
      "==================================================\n",
      "Loaded 93 selected features\n",
      "Training: (3936, 93), Validation: (984, 93)\n",
      "\n",
      "üèãÔ∏è TRAINING CHAMPION MODELS\n",
      "==================================================\n",
      "\n",
      "XGBoost Results:\n",
      "  Train Acc: 1.0000\n",
      "  Valid Acc: 1.0000\n",
      "  CV Score:  0.9995 ¬± 0.0010\n",
      "  Time:      96.71s\n",
      "\n",
      "LightGBM Results:\n",
      "  Train Acc: 1.0000\n",
      "  Valid Acc: 1.0000\n",
      "  CV Score:  0.9995 ¬± 0.0010\n",
      "  Time:      39.44s\n",
      "\n",
      "CatBoost Results:\n",
      "  Train Acc: 1.0000\n",
      "  Valid Acc: 1.0000\n",
      "  CV Score:  1.0000 ¬± 0.0000\n",
      "  Time:      129.94s\n",
      "\n",
      "RandomForest Results:\n",
      "  Train Acc: 1.0000\n",
      "  Valid Acc: 1.0000\n",
      "  CV Score:  0.9985 ¬± 0.0019\n",
      "  Time:      5.32s\n",
      "\n",
      "üéØ CREATING ENSEMBLE\n",
      "==================================================\n",
      "Top 3 models for ensemble:\n",
      "  1. CatBoost: 1.0000\n",
      "  2. XGBoost: 0.9995\n",
      "  3. LightGBM: 0.9995\n",
      "\n",
      "Voting Ensemble Results:\n",
      "  Train Acc: 1.0000\n",
      "  Valid Acc: 1.0000\n",
      "  CV Score:  1.0000 ¬± 0.0000\n",
      "  Time:      232.18s\n",
      "\n",
      "üíæ SAVING TRAINED MODELS\n",
      "==================================================\n",
      "‚úÖ Saved d:\\Portfolio\\disease\\models\\model_xgboost.pkl\n",
      "‚úÖ Saved d:\\Portfolio\\disease\\models\\model_lightgbm.pkl\n",
      "‚úÖ Saved d:\\Portfolio\\disease\\models\\model_catboost.pkl\n",
      "‚úÖ Saved d:\\Portfolio\\disease\\models\\model_randomforest.pkl\n",
      "‚úÖ Saved d:\\Portfolio\\disease\\models\\model_votingensemble.pkl\n",
      "‚úÖ All models trained and saved!\n",
      "üèÜ Ready for model_selection.ipynb\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# model_training.ipynb  |  Disease-Prediction Mini-Hackathon\n",
    "# FOCUSED: Train multiple models using selected features\n",
    "# Author: <your name>  |  Python 3.10.11\n",
    "# ======================================================================\n",
    "\n",
    "# %% [markdown]\n",
    "# # 1. Setup & Configuration\n",
    "\n",
    "# %%\n",
    "import os, warnings, logging, joblib, time\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb, lightgbm as lgb, catboost as cb\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42\n",
    "\n",
    "ROOT = Path.cwd().parent if Path.cwd().name.lower()==\"notebook\" else Path.cwd()\n",
    "PROC = ROOT / \"data\" / \"processed\" \n",
    "MODELS = ROOT / \"models\"\n",
    "\n",
    "print(\"üèãÔ∏è Model Training Pipeline\") \n",
    "print(\"=\" * 50)\n",
    "\n",
    "# %% [markdown]\n",
    "# # 2. Load Selected Features & Data\n",
    "\n",
    "# %%\n",
    "# Load selected features\n",
    "selected_features = joblib.load(MODELS / \"selected_features.pkl\")\n",
    "print(f\"Loaded {len(selected_features)} selected features\")\n",
    "\n",
    "# Load training data with selected features\n",
    "X_train = pd.read_csv(PROC / \"X_train_selected.csv\")\n",
    "y_train = pd.read_csv(PROC / \"y_train.csv\").squeeze()\n",
    "X_valid = pd.read_csv(PROC / \"X_valid_selected.csv\") \n",
    "y_valid = pd.read_csv(PROC / \"y_valid.csv\").squeeze()\n",
    "\n",
    "print(f\"Training: {X_train.shape}, Validation: {X_valid.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 3. Model Training Function\n",
    "\n",
    "# %%\n",
    "def train_evaluate_model(model, X_tr, y_tr, X_val, y_val, name):\n",
    "    \"\"\"Train and evaluate a single model\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Predictions\n",
    "    train_pred = model.predict(X_tr)\n",
    "    valid_pred = model.predict(X_val)\n",
    "    \n",
    "    # Metrics\n",
    "    train_acc = accuracy_score(y_tr, train_pred)\n",
    "    valid_acc = accuracy_score(y_val, valid_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_tr, y_tr, cv=5, scoring='accuracy')\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    results = {\n",
    "        'model': model,\n",
    "        'train_acc': train_acc,\n",
    "        'valid_acc': valid_acc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"  Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Valid Acc: {valid_acc:.4f}\")\n",
    "    print(f\"  CV Score:  {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "    print(f\"  Time:      {training_time:.2f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# %% [markdown]\n",
    "# # 4. Train Individual Models\n",
    "\n",
    "# %%\n",
    "print(\"\\nüèãÔ∏è TRAINING CHAMPION MODELS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "trained_models['XGBoost'] = train_evaluate_model(xgb_model, X_train, y_train, X_valid, y_valid, \"XGBoost\")\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    feature_fraction=0.8,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "trained_models['LightGBM'] = train_evaluate_model(lgb_model, X_train, y_train, X_valid, y_valid, \"LightGBM\")\n",
    "\n",
    "# CatBoost\n",
    "cb_model = cb.CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=SEED,\n",
    "    verbose=False\n",
    ")\n",
    "trained_models['CatBoost'] = train_evaluate_model(cb_model, X_train, y_train, X_valid, y_valid, \"CatBoost\")\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "trained_models['RandomForest'] = train_evaluate_model(rf_model, X_train, y_train, X_valid, y_valid, \"RandomForest\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 5. Create Ensemble\n",
    "\n",
    "# %%\n",
    "print(\"\\nüéØ CREATING ENSEMBLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select top 3 models for ensemble\n",
    "best_models = sorted(trained_models.items(), key=lambda x: x[1]['cv_mean'], reverse=True)[:3]\n",
    "print(\"Top 3 models for ensemble:\")\n",
    "for i, (name, results) in enumerate(best_models, 1):\n",
    "    print(f\"  {i}. {name}: {results['cv_mean']:.4f}\")\n",
    "\n",
    "# Create voting ensemble\n",
    "voting_ensemble = VotingClassifier(\n",
    "    estimators=[(name, results['model']) for name, results in best_models],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "trained_models['VotingEnsemble'] = train_evaluate_model(\n",
    "    voting_ensemble, X_train, y_train, X_valid, y_valid, \"Voting Ensemble\"\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# # 6. Save All Trained Models\n",
    "\n",
    "# %%\n",
    "print(\"\\nüíæ SAVING TRAINED MODELS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Save individual models\n",
    "for name, results in trained_models.items():\n",
    "    model_filename = MODELS / f\"model_{name.lower()}.pkl\"\n",
    "    joblib.dump(results['model'], model_filename)\n",
    "    print(f\"‚úÖ Saved {model_filename}\")\n",
    "\n",
    "# Save training results summary\n",
    "training_summary = {\n",
    "    name: {\n",
    "        'train_accuracy': float(results['train_acc']),\n",
    "        'valid_accuracy': float(results['valid_acc']),\n",
    "        'cv_mean': float(results['cv_mean']),\n",
    "        'cv_std': float(results['cv_std']),\n",
    "        'training_time': float(results['training_time'])\n",
    "    }\n",
    "    for name, results in trained_models.items()\n",
    "}\n",
    "\n",
    "with open(MODELS / \"training_results.json\", 'w') as f:\n",
    "    import json\n",
    "    json.dump(training_summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ All models trained and saved!\")\n",
    "print(f\"üèÜ Ready for model_selection.ipynb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b771982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
